{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-29T01:16:24.876036Z","iopub.execute_input":"2022-03-29T01:16:24.876791Z","iopub.status.idle":"2022-03-29T01:16:33.516499Z","shell.execute_reply.started":"2022-03-29T01:16:24.876751Z","shell.execute_reply":"2022-03-29T01:16:33.515792Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input,Dense,Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:20:26.614811Z","iopub.execute_input":"2022-03-29T01:20:26.615942Z","iopub.status.idle":"2022-03-29T01:20:28.384664Z","shell.execute_reply.started":"2022-03-29T01:20:26.615888Z","shell.execute_reply":"2022-03-29T01:20:28.383911Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/csc4851-homework4/birds_400'  \nprint(f'Directories: {os.listdir(data_dir)}')\nclasses = os.listdir(data_dir + \"/train\")\nprint(f'Number of classes: {len(classes)}')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:20:28.386388Z","iopub.execute_input":"2022-03-29T01:20:28.386669Z","iopub.status.idle":"2022-03-29T01:20:28.620755Z","shell.execute_reply.started":"2022-03-29T01:20:28.386621Z","shell.execute_reply":"2022-03-29T01:20:28.619758Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as tt\nstats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\ntrain_tfms = tt.Compose([tt.RandomCrop(224, padding=15, padding_mode='reflect'),\n                         tt.RandomHorizontalFlip(),\n                         tt.ToTensor(),\n                         tt.Normalize(*stats,inplace=True)])   \nvalid_tfms = tt.Compose([tt.ToTensor(),\n                         tt.Normalize(*stats)])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:20:28.621850Z","iopub.status.idle":"2022-03-29T01:20:28.622668Z","shell.execute_reply.started":"2022-03-29T01:20:28.622416Z","shell.execute_reply":"2022-03-29T01:20:28.622443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\ntrain_ds = ImageFolder(data_dir+'/train', train_tfms) \nvalid_ds = ImageFolder(data_dir+'/valid', valid_tfms) \ntest_ds = ImageFolder(data_dir+'/test', valid_tfms) ","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:20:28.624840Z","iopub.status.idle":"2022-03-29T01:20:28.631112Z","shell.execute_reply.started":"2022-03-29T01:20:28.628509Z","shell.execute_reply":"2022-03-29T01:20:28.628945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset_info(dataset):\n    print(f'Size of dataset: {len(dataset)}')\n    img, label = dataset[0]\n    print(f'Sample-01 Image size: {img.shape}, Label: {label}')\n    print(f'Number of classes: {len(dataset.classes)}\\n\\n')\n\nprint('Train Dataset')\ndataset_info(train_ds)\nprint('Validation Dataset')\ndataset_info(valid_ds)\nprint('Test Dataset')\ndataset_info(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:20:28.636623Z","iopub.execute_input":"2022-03-29T01:20:28.637333Z","iopub.status.idle":"2022-03-29T01:20:28.686642Z","shell.execute_reply.started":"2022-03-29T01:20:28.637292Z","shell.execute_reply":"2022-03-29T01:20:28.685174Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom cv2 import imread\nimport os\ndef get_counts(dataset_path,dataset_type):\n    all_species_count = len(os.listdir(dataset_path))\n    all_species_names=[]\n    species_image_count=[]\n    all_heights=[]\n    all_widths=[]\n    \n    for i in tqdm(os.listdir(dataset_path)):\n        all_species_names.append(i)\n        species_folder_path = dataset_path + \"/\" + i + \"/\"\n        species_image_count.append(len(os.listdir(species_folder_path)))\n        for j in os.listdir(species_folder_path):\n            filename = species_folder_path + j\n            image = imread(filename)\n            all_heights.append(image.shape[0])\n            all_widths.append(image.shape[1])\n    print()\n    print(f\"Total no. of species in {dataset_type}= {all_species_count}\")\n    return all_species_names,species_image_count,all_heights,all_widths","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:20:28.811831Z","iopub.execute_input":"2022-03-29T01:20:28.812470Z","iopub.status.idle":"2022-03-29T01:20:28.865383Z","shell.execute_reply.started":"2022-03-29T01:20:28.812423Z","shell.execute_reply":"2022-03-29T01:20:28.864639Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"train_species_names,train_species_image_count,train_images_heights,train_images_widths = get_counts(dataset_path=data_dir+\"/train/\",dataset_type=\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:20:29.006249Z","iopub.execute_input":"2022-03-29T01:20:29.006799Z","iopub.status.idle":"2022-03-29T01:22:03.828306Z","shell.execute_reply.started":"2022-03-29T01:20:29.006760Z","shell.execute_reply":"2022-03-29T01:22:03.827572Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"val_species_names,val_species_image_count,val_images_heights,val_images_widths = get_counts(dataset_path=data_dir+\"/valid\",dataset_type=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:22:03.829692Z","iopub.execute_input":"2022-03-29T01:22:03.830231Z","iopub.status.idle":"2022-03-29T01:22:07.338179Z","shell.execute_reply.started":"2022-03-29T01:22:03.830193Z","shell.execute_reply":"2022-03-29T01:22:07.337373Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"test_species_names,test_species_image_count,test_images_heights,test_images_widths = get_counts(dataset_path=data_dir+\"/test/\",dataset_type=\"test\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:22:07.339399Z","iopub.execute_input":"2022-03-29T01:22:07.339866Z","iopub.status.idle":"2022-03-29T01:22:11.093586Z","shell.execute_reply.started":"2022-03-29T01:22:07.339824Z","shell.execute_reply":"2022-03-29T01:22:11.092840Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"check = sorted(train_species_names) == sorted(val_species_names) == sorted(test_species_names)\nprint(\"Are all species names same in train, validation & test datasets? -->\",check)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:22:11.096407Z","iopub.execute_input":"2022-03-29T01:22:11.099612Z","iopub.status.idle":"2022-03-29T01:22:11.106670Z","shell.execute_reply.started":"2022-03-29T01:22:11.099580Z","shell.execute_reply":"2022-03-29T01:22:11.103713Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"for i in train_species_names:\n    \n    if (i not in val_species_names) or (i not in test_species_names):\n        print(i)\n\nprint(\"Performing set difference by subtracting the validation species names from train:-\")\nset(train_species_names).difference(set(val_species_names))\n\nprint(\"Performing set difference by subtracting the train species names from validation:-\")\nset(val_species_names).difference(set(train_species_names))\n\nprint(\"Performing set difference by subtracting the train species names from test:-\")\nset(test_species_names).difference(set(train_species_names))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:22:11.108217Z","iopub.execute_input":"2022-03-29T01:22:11.108555Z","iopub.status.idle":"2022-03-29T01:22:11.124435Z","shell.execute_reply.started":"2022-03-29T01:22:11.108519Z","shell.execute_reply":"2022-03-29T01:22:11.123652Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"os.rename(src=data_dir+\"/train/BLACK & YELLOW  BROADBILL\",dst=data_dir+\"/train/BLACK & YELLOW BROADBILL\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:22:11.125935Z","iopub.execute_input":"2022-03-29T01:22:11.126578Z","iopub.status.idle":"2022-03-29T01:22:11.153639Z","shell.execute_reply.started":"2022-03-29T01:22:11.126539Z","shell.execute_reply":"2022-03-29T01:22:11.151794Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.subplot(1,2,1)\nsns.lineplot(data=train_images_heights)\nplt.title(\"all image heights\")\nplt.xlabel(\"Height\")\n\nplt.subplot(1,2,2)\nsns.lineplot(data=train_images_widths)\nplt.title(\"all image widths\")\nplt.xlabel(\"Width\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:23:48.136780Z","iopub.execute_input":"2022-03-29T01:23:48.137560Z","iopub.status.idle":"2022-03-29T01:23:52.070005Z","shell.execute_reply.started":"2022-03-29T01:23:48.137530Z","shell.execute_reply":"2022-03-29T01:23:52.069335Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:23:52.072623Z","iopub.execute_input":"2022-03-29T01:23:52.073248Z","iopub.status.idle":"2022-03-29T01:23:52.077039Z","shell.execute_reply.started":"2022-03-29T01:23:52.073204Z","shell.execute_reply":"2022-03-29T01:23:52.076269Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/csc4851-homework4/birds_400/train'\nvalid_path = '../input/csc4851-homework4/birds_400/valid'\ntest_path = '../input/csc4851-homework4/birds_400/test'","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:23:52.078711Z","iopub.execute_input":"2022-03-29T01:23:52.079151Z","iopub.status.idle":"2022-03-29T01:23:52.086595Z","shell.execute_reply.started":"2022-03-29T01:23:52.079097Z","shell.execute_reply":"2022-03-29T01:23:52.085798Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"xcept = Xception(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:23:52.087572Z","iopub.execute_input":"2022-03-29T01:23:52.087757Z","iopub.status.idle":"2022-03-29T01:23:54.156564Z","shell.execute_reply.started":"2022-03-29T01:23:52.087733Z","shell.execute_reply":"2022-03-29T01:23:54.155761Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"for layer in xcept.layers:\n    layer.trainable = False\n\nfolders = glob('../input/csc4851-homework4/birds_400/train/*')\nx = Flatten()(xcept.output)\n\nx = layers.Dense(256, 'relu', kernel_initializer='he_normal')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.3)(x)\n\nprediction = Dense(len(folders), activation='softmax')(x)\n\nmodel = Model(inputs=xcept.input, outputs=prediction)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:24:00.544387Z","iopub.execute_input":"2022-03-29T01:24:00.545129Z","iopub.status.idle":"2022-03-29T01:24:00.652593Z","shell.execute_reply.started":"2022-03-29T01:24:00.545074Z","shell.execute_reply":"2022-03-29T01:24:00.651817Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:24:01.516678Z","iopub.execute_input":"2022-03-29T01:24:01.516938Z","iopub.status.idle":"2022-03-29T01:24:01.530166Z","shell.execute_reply.started":"2022-03-29T01:24:01.516909Z","shell.execute_reply":"2022-03-29T01:24:01.529321Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\nvalid_datagen = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = train_datagen.flow_from_directory('../input/csc4851-homework4/birds_400/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')\nvalid_set = valid_datagen.flow_from_directory('../input/csc4851-homework4/birds_400/valid',\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory('../input/csc4851-homework4/birds_400/test',\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:24:02.344947Z","iopub.execute_input":"2022-03-29T01:24:02.345308Z","iopub.status.idle":"2022-03-29T01:24:06.673162Z","shell.execute_reply.started":"2022-03-29T01:24:02.345272Z","shell.execute_reply":"2022-03-29T01:24:06.672419Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"r = model.fit(training_set,validation_data=valid_set,epochs=10,steps_per_epoch=len(training_set),validation_steps=len(valid_set))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:24:06.674783Z","iopub.execute_input":"2022-03-29T01:24:06.675485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_accuracy'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom keras.models import load_model\nmodel.save('xception.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracies=r.history['accuracy']\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = r.history['loss']\nval_losses = r.history['val_loss']\nplt.plot(train_losses, '-bx')\nplt.plot(val_losses, '-rx')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Training', 'Validation'])\nplt.title('Loss vs. No. of epochs')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom keras import losses\nfrom glob import glob\nfrom keras.preprocessing import image\ndef prepare(img_path):\n    img = image.load_img(img_path, target_size=(224,224))\n    x = image.img_to_array(img)\n    x = x/224\n    return np.expand_dims(x, axis=0)\n\ncce = losses.CategoricalCrossentropy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"template = [0]*400\nlog_loss = {}\ntest_images = glob(\"/kaggle/input/csc4851-homework4/birds_400/test/\" + \"*/*.jpg\")\n\nfor path in test_images:\n    result = model.predict([prepare(path)])\n    actual_class = path.split('/')[-2]\n    actual_class = \"BLACK & YELLOW  BROADBILL\" if actual_class == \"BLACK & YELLOW BROADBILL\" else actual_class\n    actual_index = classes.index(actual_class)\n    template[actual_index] = 1\n    log_loss_current = cce(template, result[0]).numpy()\n    if actual_index in log_loss:\n        log_loss[actual_index] += (log_loss_current)/100\n    else:\n        log_loss[actual_index] = (log_loss_current)/100\n    template[actual_index] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"log_loss","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nids = list(log_loss.keys())\nvalues = list(log_loss.values())\nf = open('submission.csv', 'w')\nwriter = csv.writer(f)\nwriter.writerow(['id','birds'])\nfor index in range(len(ids)):\n    writer.writerow([ids[index],values[index]])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}