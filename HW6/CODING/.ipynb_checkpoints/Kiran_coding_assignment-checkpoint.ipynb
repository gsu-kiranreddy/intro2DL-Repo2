{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:51.161763Z",
     "iopub.status.busy": "2022-01-22T15:55:51.161511Z",
     "iopub.status.idle": "2022-01-22T15:55:51.165623Z",
     "shell.execute_reply": "2022-01-22T15:55:51.164626Z",
     "shell.execute_reply.started": "2022-01-22T15:55:51.161734Z"
    },
    "id": "DFvVsyDD7vZk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SpIapruxACqW"
   },
   "outputs": [],
   "source": [
    "# !pip install -U torch==1.8.0 torchtext==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpHbgTXO__UU"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBxqyVR38bQ3"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "upload = files.upload()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pwgq4LLO7vZp"
   },
   "source": [
    "# Import Required Libraries & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:51.178773Z",
     "iopub.status.busy": "2022-01-22T15:55:51.178323Z",
     "iopub.status.idle": "2022-01-22T15:55:52.913605Z",
     "shell.execute_reply": "2022-01-22T15:55:52.912893Z",
     "shell.execute_reply.started": "2022-01-22T15:55:51.178736Z"
    },
    "id": "V7_dOfgn7vZr"
   },
   "outputs": [],
   "source": [
    "#importing the training data\n",
    "df=pd.read_csv('IMDB_Dataset.csv')\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdhzYJJP8MsH"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eqEpMboa7vZs"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_BgNkzE87vZt"
   },
   "outputs": [],
   "source": [
    "df.loc[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lxf-P-ws7vZu"
   },
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:52.915240Z",
     "iopub.status.busy": "2022-01-22T15:55:52.914817Z",
     "iopub.status.idle": "2022-01-22T15:55:52.931074Z",
     "shell.execute_reply": "2022-01-22T15:55:52.930198Z",
     "shell.execute_reply.started": "2022-01-22T15:55:52.915202Z"
    },
    "id": "vmKCJKZR7vZv"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "sentiment : 0 = negative, 1 = positive \n",
    "use the following to get the sentiment of a sentence :  \n",
    "sentiment = 0 if sentiment is negative else 1\n",
    "\n",
    "\n",
    "use np.where to get the sentiment of a sentence :\n",
    "\"\"\"\n",
    "df['sentiment'] = np.where(df['sentiment'] == 'positive', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:52.933556Z",
     "iopub.status.busy": "2022-01-22T15:55:52.933295Z",
     "iopub.status.idle": "2022-01-22T15:55:52.942961Z",
     "shell.execute_reply": "2022-01-22T15:55:52.942162Z",
     "shell.execute_reply.started": "2022-01-22T15:55:52.933524Z"
    },
    "id": "XIKJAg7F7vZw"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:52.944777Z",
     "iopub.status.busy": "2022-01-22T15:55:52.944484Z",
     "iopub.status.idle": "2022-01-22T15:55:52.951178Z",
     "shell.execute_reply": "2022-01-22T15:55:52.950461Z",
     "shell.execute_reply.started": "2022-01-22T15:55:52.944743Z"
    },
    "id": "h0PFK-A67vZx"
   },
   "outputs": [],
   "source": [
    "df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JUEjzJRr7vZz"
   },
   "outputs": [],
   "source": [
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "\n",
    "print(\"the device being used is \", DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bDaZQMOr7vZy"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Load the spacy model and load the English language model from https://spacy.io/usage/models\n",
    "\"\"\"\n",
    "#loading the spacy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "### ADD YOUR SPACY MODEL HERE ###\n",
    "\n",
    "# python -m spacy download en_core_web_sm\n",
    "# import spacy\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# https://spacy.io/usage/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fk9cJb0i7vZ0"
   },
   "outputs": [],
   "source": [
    "# general Settings\n",
    "\n",
    "RANDOM_SEED = 26\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "VOCABULARY_SIZE = 15000\n",
    "### ADD YOUR LEARNING RATE HERE ###\n",
    "LEARNING_RATE = 0.002\n",
    "### ADD YOUR BATCH SIZE HERE ###\n",
    "BATCH_SIZE = 112\n",
    "### ADD YOUR NUMBER OF EPOCHS HERE ###\n",
    "NUM_EPOCHS = 20\n",
    "### ADD YOUR EMBEDDING DIMENSION HERE ###\n",
    "EMBEDDING_DIM = 400\n",
    "### ADD YOUR HIDDEN DIMENSION HERE ###\n",
    "HIDDEN_DIM = 64\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5JZXCtrr7vZ0"
   },
   "source": [
    "# Text & label Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:53.639530Z",
     "iopub.status.busy": "2022-01-22T15:55:53.639045Z",
     "iopub.status.idle": "2022-01-22T15:55:54.191068Z",
     "shell.execute_reply": "2022-01-22T15:55:54.190361Z",
     "shell.execute_reply.started": "2022-01-22T15:55:53.639494Z"
    },
    "id": "tixwYGDR7vZ1"
   },
   "outputs": [],
   "source": [
    "# Define feature processing\n",
    "\"\"\"\n",
    "Define the fields for the data.\n",
    "\"\"\"\n",
    "TEXT = torchtext.legacy.data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:54.194504Z",
     "iopub.status.busy": "2022-01-22T15:55:54.194231Z",
     "iopub.status.idle": "2022-01-22T15:55:54.198370Z",
     "shell.execute_reply": "2022-01-22T15:55:54.197471Z",
     "shell.execute_reply.started": "2022-01-22T15:55:54.194470Z"
    },
    "id": "33_4zFKJ7vZ1"
   },
   "outputs": [],
   "source": [
    "# Define Label processing\n",
    "LABEL = torchtext.legacy.data.LabelField(dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:55:54.200276Z",
     "iopub.status.busy": "2022-01-22T15:55:54.199959Z",
     "iopub.status.idle": "2022-01-22T15:55:57.099915Z",
     "shell.execute_reply": "2022-01-22T15:55:57.099168Z",
     "shell.execute_reply.started": "2022-01-22T15:55:54.200243Z"
    },
    "id": "LKZl7rAK7vZ2"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the fields for the data.\n",
    "\"\"\"\n",
    "\n",
    "df.to_csv('moviedata.csv', index = None)\n",
    "df = pd.read_csv('moviedata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jABPSqax7vZ3"
   },
   "outputs": [],
   "source": [
    "# process the dataset\n",
    "# TEXT = LABEL = []\n",
    "fields = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\n",
    "\n",
    "dataset = torchtext.legacy.data.TabularDataset(\n",
    "                    ### ADD YOUR DATASET PATH HERE ###\n",
    "                    path = '/content/moviedata.csv',\n",
    "                    ### ADD YOUR DATASET FORMAT HERE ###\n",
    "                    format = 'csv', \n",
    "                    ### ADD YOUR SKIP HEADER HERE ###\n",
    "                    skip_header = True,  \n",
    "                    ### ADD YOUR FIELDS HERE ### \n",
    "                    fields =  fields\n",
    ")\n",
    "\n",
    "#classtorchtext.data.TabularDataset(path, format, fields, skip_header=False, csv_reader_params={}, **kwargs)\n",
    "#classtorchtext.data.TabularDataset(path, format, fields, skip_header=False, csv_reader_params={}, **kwargs)\n",
    "#https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.TabularDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjS-rBzR7vZ3"
   },
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:56:41.890714Z",
     "iopub.status.busy": "2022-01-22T15:56:41.890459Z",
     "iopub.status.idle": "2022-01-22T15:56:41.961168Z",
     "shell.execute_reply": "2022-01-22T15:56:41.960371Z",
     "shell.execute_reply.started": "2022-01-22T15:56:41.890680Z"
    },
    "id": "z5p0EVPC7vZ3"
   },
   "outputs": [],
   "source": [
    "# Split dataset into train and test set\n",
    "\n",
    "train_data, test_data = dataset.split(split_ratio = [0.8, 0.2], random_state = random.seed(RANDOM_SEED))\n",
    "\n",
    "print('Length of train data', len(train_data))\n",
    "print('Length of test data', len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:56:41.962867Z",
     "iopub.status.busy": "2022-01-22T15:56:41.962611Z",
     "iopub.status.idle": "2022-01-22T15:56:42.018970Z",
     "shell.execute_reply": "2022-01-22T15:56:42.017378Z",
     "shell.execute_reply.started": "2022-01-22T15:56:41.962832Z"
    },
    "id": "Vq2je1m27vZ4"
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_data.split(split_ratio = [0.85, 0.15], random_state = random.seed(RANDOM_SEED))\n",
    "\n",
    "print('Length of train data', len(train_data))\n",
    "print('Length of valid data', len(val_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku8joKfR7vZ4"
   },
   "source": [
    "# Data Observation after Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:56:42.020384Z",
     "iopub.status.busy": "2022-01-22T15:56:42.020132Z",
     "iopub.status.idle": "2022-01-22T15:56:42.026208Z",
     "shell.execute_reply": "2022-01-22T15:56:42.025377Z",
     "shell.execute_reply.started": "2022-01-22T15:56:42.020349Z"
    },
    "id": "IKQ6aApz7vZ5"
   },
   "outputs": [],
   "source": [
    "# Look at first traning example\n",
    "\n",
    "print(vars(train_data.examples[2000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:56:42.028212Z",
     "iopub.status.busy": "2022-01-22T15:56:42.027904Z",
     "iopub.status.idle": "2022-01-22T15:56:43.688300Z",
     "shell.execute_reply": "2022-01-22T15:56:43.687534Z",
     "shell.execute_reply.started": "2022-01-22T15:56:42.028178Z"
    },
    "id": "a6-NqW1J7vZ5"
   },
   "outputs": [],
   "source": [
    "# Build Vocabulary\n",
    "\n",
    "TEXT.build_vocab(train_data, max_size = VOCABULARY_SIZE)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'vocabulary size: {len(TEXT.vocab)}')\n",
    "print(f'Label Size: {len(LABEL.vocab)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYNdv-3u7vZ6"
   },
   "source": [
    " 2 extra value in vocabulary is because added (unknown) and (padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v_Rm8a-XQASH"
   },
   "outputs": [],
   "source": [
    "# self.text = data.Field(\n",
    "#             tokenize=tokenizer,\n",
    "#             lower=True,\n",
    "#             include_lengths=True,\n",
    "#             preprocessing=generate_n_grams,\n",
    "#         )\n",
    "# https://discuss.pytorch.org/t/save-and-loading-vocabulary/83173\n",
    "# self.text.vocab.freqs.most_common(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M0RwGmsR7vZ6"
   },
   "outputs": [],
   "source": [
    "# Print the most common words: Use the most_common method of the TEXT vocabulary\n",
    "most_common_words = TEXT.vocab.freqs.most_common(25)\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:56:43.727759Z",
     "iopub.status.busy": "2022-01-22T15:56:43.727533Z",
     "iopub.status.idle": "2022-01-22T15:56:43.733148Z",
     "shell.execute_reply": "2022-01-22T15:56:43.732231Z",
     "shell.execute_reply.started": "2022-01-22T15:56:43.727727Z"
    },
    "id": "bAPOLNaK7vZ6"
   },
   "outputs": [],
   "source": [
    "# Token corresponding to first 10 Indices\n",
    "\n",
    "print(TEXT.vocab.itos[:20]) #itos = Integer to string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hPWpeis37vZ7"
   },
   "source": [
    "# Data Preparation for Batch wise Implimentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8mAapN37vZ7"
   },
   "outputs": [],
   "source": [
    "# Define Dataloader\n",
    "\n",
    "# classmethodsplits(path=None, root='.data', train=None, validation=None, test=None, **kwargs)\n",
    "# Create Dataset objects for multiple splits of a dataset.\n",
    "\n",
    "# Parameters:\t\n",
    "# path (str) – Common prefix of the splits’ file paths, or None to use the result of cls.download(root).\n",
    "# root (str) – Root dataset storage directory. Default is ‘.data’.\n",
    "# train (str) – Suffix to add to path for the train set, or None for no train set. Default is None.\n",
    "# validation (str) – Suffix to add to path for the validation set, or None for no validation set. Default is None.\n",
    "# test (str) – Suffix to add to path for the test set, or None for no test set. Default is None.\n",
    "# keyword arguments (Remaining) – Passed to the constructor of the Dataset (sub)class being used.\n",
    "# Returns:\t\n",
    "# Datasets for train, validation, and test splits in that order, if provided.\n",
    "\n",
    "# Return type:\t\n",
    "# Tuple[Dataset]\n",
    "\n",
    "# https://torchtext.readthedocs.io/en/latest/data.html#torchtext.data.Dataset.splits\n",
    "\n",
    "train_loader, valid_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n",
    "        ### ADD YOUR SPLIT DATA HERE (Make sure you add it in a tuple) ###\n",
    "        #Adding in form of a tuple\n",
    "        (train_data, val_data, test_data), \n",
    "        ### ADD YOUR BATCH SIZE HERE ###\n",
    "        batch_size = 64,\n",
    "        ### ADD YOUR SORT WITHIN BATCH HERE ### \n",
    "        sort_within_batch = False, \n",
    "        #using the lambda function to sort\n",
    "        sort_key = lambda x : len(x.TEXT_COLUMN_NAME), \n",
    "        device = DEVICE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRKCWdu-T5Bg"
   },
   "outputs": [],
   "source": [
    "#  Group similar length text sequences together in batches.\n",
    "# torchtext_train_dataloader, torchtext_valid_dataloader = torchtext.data.BucketIterator.splits(\n",
    "    \n",
    "#                               # Datasets for iterator to draw data from\n",
    "#                               (train_dataset, valid_dataset),\n",
    "\n",
    "#                               # Tuple of train and validation batch sizes.\n",
    "#                               batch_sizes=(train_batch_size, valid_batch_size),\n",
    "\n",
    "#                               # Device to load batches on.\n",
    "#                               device=device, \n",
    "\n",
    "#                               # Function to use for sorting examples.\n",
    "#                               sort_key=lambda x: len(x['text']),\n",
    "\n",
    "\n",
    "#                               # Repeat the iterator for multiple epochs.\n",
    "#                               repeat=True, \n",
    "\n",
    "#                               # Sort all examples in data using `sort_key`.\n",
    "#                               sort=False, \n",
    "\n",
    "#                               # Shuffle data on each epoch run.\n",
    "#                               shuffle=True,\n",
    "\n",
    "#                               # Use `sort_key` to sort examples in each batch.\n",
    "#                               sort_within_batch=True,\n",
    "#                               )\n",
    "\n",
    "# # Print number of batches in each split.\n",
    "# print('Created `torchtext_train_dataloader` with %d batches!'%len(torchtext_train_dataloader))\n",
    "# print('Created `torchtext_valid_dataloader` with %d batches!'%len(torchtext_valid_dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bRyA_eX6T9V8"
   },
   "outputs": [],
   "source": [
    "# # Loop through regular dataloader.\n",
    "# print('PyTorch DataLoader\\n')\n",
    "# for batch in torch_train_dataloader:\n",
    "  \n",
    "#   # Let's check batch size.\n",
    "#   print('Batch size: %d\\n'% len(batch['text']))\n",
    "#   print('LABEL\\tLENGTH\\tTEXT'.ljust(10))\n",
    "\n",
    "#   # Print each example.\n",
    "#   for text, label in zip(batch['text'], batch['label']):\n",
    "#     print('%s\\t%d\\t%s'.ljust(10) % (label, len(text), text))\n",
    "#   print('\\n')\n",
    "  \n",
    "#   # Only look at first batch. Reuse this code in training models.\n",
    "#   break\n",
    "  \n",
    "\n",
    "# # Create batches - needs to be called before each loop.\n",
    "# torchtext_train_dataloader.create_batches()\n",
    "\n",
    "# # Loop through BucketIterator.\n",
    "# print('PyTorchText BuketIterator\\n')\n",
    "# for batch in torchtext_train_dataloader.batches:\n",
    "\n",
    "#   # Let's check batch size.\n",
    "#   print('Batch size: %d\\n'% len(batch))\n",
    "#   print('LABEL\\tLENGTH\\tTEXT'.ljust(10))\n",
    "  \n",
    "#   # Print each example.\n",
    "#   for example in batch:\n",
    "#     print('%s\\t%d\\t%s'.ljust(10) % (example['label'], len(example['text']), example['text']))\n",
    "#   print('\\n')\n",
    "  \n",
    "#   # Only look at first batch. Reuse this code in training models.\n",
    "#   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:56:43.768827Z",
     "iopub.status.busy": "2022-01-22T15:56:43.768197Z",
     "iopub.status.idle": "2022-01-22T15:56:43.900963Z",
     "shell.execute_reply": "2022-01-22T15:56:43.900283Z",
     "shell.execute_reply.started": "2022-01-22T15:56:43.768790Z"
    },
    "id": "R2R9FO567vZ7"
   },
   "outputs": [],
   "source": [
    "# Testing the iterators (note that the number of rows depends on the longest document in the respective batch):\n",
    "\n",
    "print('Train')\n",
    "for batch in train_loader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nValid:')\n",
    "for batch in valid_loader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break\n",
    "    \n",
    "print('\\nTest:')\n",
    "for batch in test_loader:\n",
    "    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n",
    "    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eRy7i9qz7vZ8"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hgYGyzB67vZ9"
   },
   "outputs": [],
   "source": [
    "\n",
    "class RNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        ### ADD YOUR CODE HERE ###\n",
    "        self.embedding = nn.Embedding(input_dim,\n",
    "                                      embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, \n",
    "                          hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, \n",
    "                            output_dim)\n",
    "        ### END YOUR CODE ### \n",
    "\n",
    "    def forward(self, text):\n",
    "        ### ADD YOUR CODE HERE ###\n",
    "        embedded = self.embedding(text)\n",
    "        output = self.fc(hidden.squeeze(0))\n",
    "        hidden = self.rnn(embedded)\n",
    "        # text dim: [sentence length, batch size]\n",
    "    \n",
    "        # embedded dim: [sentence length, batch size, embedding dim]\n",
    "        \n",
    "        # output dim: [sentence length, batch size, hidden dim]\n",
    "        # hidden dim: [1, batch size, hidden dim]\n",
    "\n",
    "        # hidden dim: [batch size, hidden dim]\n",
    "\n",
    "        ### END YOUR CODE ###\n",
    "                \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6prmOPz97vZ9"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "model = RNN(input_dim=30000, ### ADD YOUR INPUT DIM HERE. This can be the length of your vocabulary or the embedding dim ###\n",
    "            embedding_dim=EMBEDDING_DIM, ### ADD YOUR EMBEDDING DIM HERE ###\n",
    "            hidden_dim=HIDDEN_DIM, ### ADD YOUR HIDDEN DIM HERE ###\n",
    "            output_dim=2  ### ADD NUMBER OF CLASSES HERE ###\n",
    ")\n",
    "\n",
    "# model = model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pK_ilsqz7vZ-"
   },
   "source": [
    "# Define Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T15:56:51.581205Z",
     "iopub.status.busy": "2022-01-22T15:56:51.580712Z",
     "iopub.status.idle": "2022-01-22T15:56:51.589897Z",
     "shell.execute_reply": "2022-01-22T15:56:51.588931Z",
     "shell.execute_reply.started": "2022-01-22T15:56:51.581131Z"
    },
    "id": "RlVdnrGF7vZ-"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "    with torch.no_grad():\n",
    "        correct_pred, num_examples = 0, 0\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "            features = features.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            logits = model(features)\n",
    "            _, predicted_labels = torch.max(logits, 1)\n",
    "            num_examples += targets.size(0)\n",
    "            correct_pred += (predicted_labels == targets).sum()\n",
    "    return correct_pred.float()/num_examples * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dbwxN8O27vZ-"
   },
   "source": [
    "# Model Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wxNDl7YeNBC7"
   },
   "outputs": [],
   "source": [
    "# loss = nn.BCEWithLogitsLoss()\n",
    "# input = torch.randn(3, requires_grad=True)\n",
    "# target = torch.empty(3).random_(2)\n",
    "# output = loss(input, target)\n",
    "# output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xihUNUCi7vZ_"
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "  model.train()\n",
    "  for batch_idx, batch_data in enumerate(train_loader):\n",
    "\n",
    "      text = batch_data.TEXT_COLUMN_NAME.to(DEVICE)\n",
    "      labels = batch_data.LABEL_COLUMN_NAME.to(DEVICE)\n",
    "        ### FORWARD AND BACK PROP\n",
    "      optimizer.zero_grad()    \n",
    "      predictions = model(batch.text).squeeze(1) \n",
    "       # torch.nn.functional.cross_entropy(input, \n",
    "        # target, \n",
    "        # weight=None,\n",
    "        #  size_average=None, \n",
    "        #  ignore_index=- 100, \n",
    "        #  reduce=None, \n",
    "        #  reduction='mean', \n",
    "        #  label_smoothing=0.0)\n",
    "      loss = nn.functional.cross_entropy(\n",
    "            predictions,\n",
    "            labels)\n",
    "      loss.backward()\n",
    "        ### UPDATE MODEL PARAMETERS\n",
    "        \n",
    "        ### LOGGING\n",
    "      if not batch_idx % 50:\n",
    "        print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
    "                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n",
    "                   f'Loss: {loss:.4f}')\n",
    "\n",
    "  with torch.set_grad_enabled(False):\n",
    "        print(f'training accuracy: '\n",
    "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
    "              f'\\nvalid accuracy: '\n",
    "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
    "  print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
    "    \n",
    "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
    "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlVljA9ersko"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOZjfOYeruzJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2YCFG7477vZ_"
   },
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T16:41:22.981494Z",
     "iopub.status.busy": "2022-01-22T16:41:22.981224Z",
     "iopub.status.idle": "2022-01-22T16:41:23.185798Z",
     "shell.execute_reply": "2022-01-22T16:41:23.185126Z",
     "shell.execute_reply.started": "2022-01-22T16:41:22.981459Z"
    },
    "id": "42pXYBud7vZ_"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "def predict_sentiment(model, sentence):\n",
    "\n",
    "    model.eval()\n",
    "    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n",
    "    return prediction[0][1].item()\n",
    "\n",
    "print('Probability positive:')\n",
    "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-22T16:41:49.753493Z",
     "iopub.status.busy": "2022-01-22T16:41:49.752937Z",
     "iopub.status.idle": "2022-01-22T16:41:49.762087Z",
     "shell.execute_reply": "2022-01-22T16:41:49.761053Z",
     "shell.execute_reply.started": "2022-01-22T16:41:49.753453Z"
    },
    "id": "Sw67HAXm7vaA"
   },
   "outputs": [],
   "source": [
    "print('Probability positive:')\n",
    "predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LB_OiNA7vaA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "coding_assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
